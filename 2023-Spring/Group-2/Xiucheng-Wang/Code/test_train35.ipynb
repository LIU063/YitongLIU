{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, Sigmoid, BatchNorm1d as BN, ReLU6 as ReLU6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layouts = 100000\n",
    "test_layouts = 2000\n",
    "\n",
    "train_n = 70\n",
    "test_n  = [4,5,6,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generate(n_node,K):\n",
    "    inputs = np.zeros((K,n_node))\n",
    "    label = np.zeros((K,n_node))\n",
    "    for i_sample in range(K):\n",
    "        x = np.random.random(n_node)\n",
    "        y = []\n",
    "        for i in range(n_node):\n",
    "            y_ = x.copy()[i]\n",
    "            x_copy    = np.delete(x.copy(),i)\n",
    "            max_index = np.argmax(x_copy)\n",
    "            x_copy    = np.sort(np.delete(x_copy,max_index))\n",
    "            for j in range(n_node-2):\n",
    "                y_ += (x_copy[j]**2)*x_copy[n_node-3-j]\n",
    "            y.append(y_/n_node)\n",
    "        y = np.array(y)\n",
    "        inputs[i_sample] = x\n",
    "        label[i_sample]  = y\n",
    "    return inputs,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCDataset(DGLDataset):\n",
    "    def __init__(self, data, label,n_node):\n",
    "        self.data = data\n",
    "        self.n_node = n_node\n",
    "        self.label = np.expand_dims(label, axis = -1)\n",
    "        self.get_cg()\n",
    "        super().__init__(name='power_control')\n",
    "        \n",
    "        \n",
    "    def build_graph(self, idx): \n",
    "        H = self.data[idx,:]\n",
    "        \n",
    "        graph = dgl.graph(self.adj, num_nodes=self.n_node)\n",
    "        \n",
    "        node_features = torch.tensor(np.expand_dims(H,axis=1), dtype = torch.float)\n",
    "        ## Node feature of the k-th node is the direct link channel of k-th pair\n",
    "        node_labels = torch.tensor(self.label[idx,:], dtype = torch.float)\n",
    "        ## Node label is the power obtained by FPlinQ\n",
    "        \n",
    "        # edge_features  = []\n",
    "        # for e in self.adj:\n",
    "        #     edge_features.append([H[e[0],e[1]],H[e[1],e[0]]])\n",
    "        ## Edge feature between node e[0] and e[1] is the interference channel between e[0]-th pair and e[1]-th pair\n",
    "\n",
    "        graph.ndata['feat'] = node_features\n",
    "        graph.ndata['label'] = node_labels\n",
    "        # graph.edata['feat'] = torch.tensor(edge_features, dtype = torch.float)\n",
    "        return graph\n",
    "    \n",
    "    def get_cg(self):\n",
    "        ## The graph is a complete graph\n",
    "        self.adj = []\n",
    "        for i in range(0,self.n_node):\n",
    "            for j in range(0,self.n_node):\n",
    "                if(not(i==j)):\n",
    "                    self.adj.append([i,j])\n",
    "                    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        return self.graph_list[index]\n",
    "\n",
    "    def process(self):\n",
    "        n = len(self.data)\n",
    "        self.graph_list = []\n",
    "        for i in range(n):\n",
    "            graph = self.build_graph(i)\n",
    "            self.graph_list.append(graph)\n",
    "\n",
    "def collate(samples):\n",
    "    '''DGL collate function'''\n",
    "    graphs = samples\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data_generate(train_n, train_layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list = []\n",
    "for n_test in test_n:\n",
    "    x_test, y_test = data_generate(n_test, test_layouts)\n",
    "    test_data_list.append((x_test, y_test,n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PCDataset(x_train, y_train, train_n)\n",
    "test_data_list = [PCDataset(x_test, y_test, n_test) for (x_test, y_test, n_test) in test_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate)\n",
    "test_loader_list = [DataLoader(test_data_list[i], test_layouts, shuffle=False, collate_fn=collate) for i in range(len(test_n))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, mlp, **kwargs):\n",
    "        super(EdgeConv, self).__init__()\n",
    "        self.mlp = mlp\n",
    "        #self.reset_parameters()\n",
    "\n",
    "    def concat_message_function(self, edges):\n",
    "        return {'out': torch.cat([edges.src['hid'], edges.dst['hid']], axis=1)}\n",
    "    \n",
    "    def forward(self, g):\n",
    "        g.apply_edges(self.concat_message_function)\n",
    "        g.edata['out'] = self.mlp(g.edata['out'])\n",
    "        g.update_all(fn.copy_e('out', 'm'),\n",
    "                     fn.max('m', 'hid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = EdgeConv(MLP([2, 16]))\n",
    "        self.conv2 = EdgeConv(MLP([2*16, 32]))\n",
    "        self.mlp = MLP([32, 16])\n",
    "        self.mlp = Seq(*[self.mlp, Seq(Lin(16, 1))])\n",
    "\n",
    "    def forward(self, g):\n",
    "        g.ndata['hid'] = g.ndata['feat']\n",
    "        self.conv1(g)\n",
    "        self.conv2(g)\n",
    "        out = self.mlp(g.ndata['hid'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for batch_idx, g in enumerate(train_loader):\n",
    "        #data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        g = g.to(\"cuda:0\")\n",
    "        output = model(g)\n",
    "        loss = F.mse_loss(output, g.ndata['label'])\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * len(g.ndata['feat'])\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, train_K, test_mode = False):\n",
    "    model.eval()\n",
    "    mse = nmse = 0\n",
    "    for i,g in enumerate(loader) :\n",
    "        n = len(g.ndata['feat'])\n",
    "        bs = len(g.ndata['feat'])//train_K\n",
    "        g = g.to(\"cuda:0\")\n",
    "        output = model(g).reshape(bs,-1)\n",
    "        y_test = g.ndata['label'].reshape(bs,-1)\n",
    "        loss = F.mse_loss(output, y_test)\n",
    "        mse += loss.item() * bs\n",
    "        # if i==0:\n",
    "        #     print(output.shape)\n",
    "        if test_mode:\n",
    "            nmse += (((output - y_test)**2).sum(axis = -1)/(y_test**2).sum(axis = -1)).sum().item()\n",
    "    if test_mode:\n",
    "        return mse / len(loader.dataset), nmse / len(loader.dataset)\n",
    "    return mse / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Train Loss: 0.0307 Val MSE: 0.0748, 0.0643, 0.0573, 0.0329, \n",
      "\n",
      "Epoch 001, Train Loss: 0.0017 Val MSE: 11.5856, 6.6241, 4.2646, 0.0066, \n",
      "\n",
      "Epoch 002, Train Loss: 0.0012 Val MSE: 10.7167, 5.9837, 3.8112, 0.0048, \n",
      "\n",
      "Epoch 003, Train Loss: 0.0011 Val MSE: 10.1985, 5.6252, 3.5651, 0.0042, \n",
      "\n",
      "Epoch 004, Train Loss: 0.0009 Val MSE: 10.5501, 5.8063, 3.6765, 0.0033, \n",
      "\n",
      "Epoch 005, Train Loss: 0.0009 Val MSE: 10.3010, 5.5790, 3.5104, 0.0035, \n",
      "\n",
      "Epoch 006, Train Loss: 0.0008 Val MSE: 9.7856, 5.3010, 3.3344, 0.0029, \n",
      "\n",
      "Epoch 007, Train Loss: 0.0008 Val MSE: 9.7293, 5.1906, 3.2431, 0.0031, \n",
      "\n",
      "Epoch 008, Train Loss: 0.0008 Val MSE: 9.6087, 5.1152, 3.1969, 0.0030, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 20):\n",
    "    if(epoch % 1 == 0):\n",
    "        loss = test(train_loader,train_n)\n",
    "        print('Epoch {:03d}, Train Loss: {:.4f}'.format(epoch, loss),end=\" \")\n",
    "        print(\"Val MSE:\", end=\" \")\n",
    "        for (loader, n_test) in zip(test_loader_list,test_n):\n",
    "            mse, nmse = test(loader, n_test, True)\n",
    "            print('{:.4f}'.format(mse),end=\", \")\n",
    "        print(\"\\n\")\n",
    "    train(epoch)\n",
    "    #scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dglcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
