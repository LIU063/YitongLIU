<p id="table"></p>

# Table of Contents

- <a href="#1">Week 1 (2023.3.23)</a>
- <a href="#2">Week 2 (2023.3.30)</a>
- <a href="#3">Week 3 (2023.4.6)</a>  
- <a href="#4">Week 4 (2023.4.13)</a>
- <a href="#5">Week 5 (2023.4.19)</a>


<br/>  

<p id="1"></p>  

# 3月23日周报

## 学习内容：

 1.学习了一下KL散度和匈牙利算法，尝试对算法利用匈牙利算法进行两两配对，从而构造一种新型拓扑结构
 2.学习沈师兄写的代码和之前的相关工作。
 3.匹配好的客户端如何再利用联邦分割进行训练有了一定的思路。目前算法思路如下：
### 算法：好朋友sfl
服务器初始化W层模型的模型参数定义为 $W_0 $，客户端上传自身的状态信息（ $D_i$ ，数据集大小; $C_i$ :计算能力; $P_i$ 数据集数据分布,   $(X_i,Y_i)$    位置坐标)
服务器根据各客户端上传的状态信息，主要是数据分布之间的差异性以及计算能力,还有通信范围与位置远近，根据匈牙利算法算好匹配搭档。
匹配具体流程：
首先根据客户端其距离远近，计算能力，数据异质性的差异映射到权重矩阵里，然后利用匈牙利算法得到最佳匹配值。     
具体如下：位置差异：将客户端Ui位置分别定义成   $(X_i,Y_i)$   ,客户端之间的间隔距离是 $disti=(X_i-X_j)^2＋（Y_i-Y_j)^2$ 将通信范围定义100,有两种特殊情况，若间隔距离都大于100，或者算的自己与自己的位置距离，我们将这两种特殊情况下通信距离都定义成无穷。总的生成的位置差异矩阵设成 `dist_ matrix` 。

计算能力：不同客户端的计算能力定义成 $C_i$ ，显然那计算能力的差异可以用最小二乘法表示成         $(C_i-C_j)^2$        ，当是自己和自己的时候，这种情况不是我们想要考虑的，所以我们将其设为-1.总的计算能力矩阵我们将其定义成 $C$ 

数据异质性：根据客户端定义几种不同类型的分布，此处定义成均匀，高斯，对数，指数分布的数据，然后我们利用迪利克雷分布将其范围缩至 $(0,1)$ 之间，再利用Kl散度分别表示出不同分布之间的差异值，由于KL散度正常情况输出值也肯定是非负数，所以自己和自己计算时，我们将其KL散度设置成为-1.总的数据差异矩阵设为d.
数据集大小的差异：     `dataset_ size_ difference`   ，也用最小二乘法表示。

位置差异，计算能力，数据异质性我们解决之后，我们将其映射到一个w权重矩阵里，定义成             $w = dist\\_matrix / (1/2 * c + 1/4* d+1/4*dataset\\_size\\_difference)$        

再根据匈牙利算法输入我们的成本矩阵W，然后得到最佳匹配的结果      $（U_i，V_j)$        。
同时服务器计算客户端的向前传播步长和总聚合权重（这里总聚合权重主要指配对后的两个客户端当作一个整体，每个整体之间的总数据集的大小显然不同，为了方便之后服务器聚合时加权进行，故需要定义。）组队后将其定义为       $M$      ，每两个组队后的客户端将其定义成一个      $M_i$       ,M中一共包含M个        $M_i$       ，即组队后的两个小客户端的数据集总数为      $D$       ，即每一个      $D_i$      里面是     $d_i$      的大小加上     $d_j$      的大小，由此算出组队后聚合权重是              $Ai=\frac{D_i}{\sum_{r=1}^m D_i}$              ，服务器计算其传播步骤                $L_i=\frac{C_i}{C_i+C_j}W$             ;(此处的i,j是匹配好的对应的结果）,内部聚合权重为                     $a_i=\frac{d_i}{d_i+d_j}$             .     
其中一个小客户端相较于所有客户端聚合权重其实应是       $A_j * a_i$       服务器发送（   $W_0$     ,匹配好的搭档     $V_j$  ,     $L_i$    ,      $a_i$    )给每个客户端      $U_i$        。
图片是目前设想的伪代码：
<img width="548" alt="屏幕截图 2023-03-22 195316" src="https://user-images.githubusercontent.com/122032188/226929365-e7da4f36-97b7-4084-9b17-cdc19c18d5f3.png">

 
里面具体内部向前传播过程
在环内正常情况会产生2个客户端，他们的位置距离是很近的，这个因素在传播过程中就不需要再考虑了。
在每个通信轮次中，匹配后的两个客户端和两个客户端之间是没有通信的，但是匹配后客户端和服务器之间是并联的，每个客户端的前向传播可以分成2个部分；我们将这两个客户端分别设置为A，B。假设一个神经网络的层数一共有N+1层，即A拥有的神经网络层数Fa←{L0，L1，...Ln},B拥有的神经网络层数Fb←{Ln+1,Ln+2,...LN}。
### 6G大会相关内容
对6G的概念有了一定的认知，同时对6G的相关创新有所了解，例如基于现今无线网络的新通信方法必然产生，包括THZ和RISs,AI通信，以及其适应性和可持续性方面的考虑；然后计算创新方面：主要是基于边缘创新方面，关于AI创新主要是知识驱动，至于AI那种是我们需要的？有几个方面：解释性（即所有模型必须执行可解释性的决定和预测）；有根据性（即所有模型都有能力去分析，理解，和重现）概括性（即所有模型有泛化能力，和可转移的学习能力）分割和合作性（这个应该就是联邦学习方面的研究），绿色可持续性，以及终身和可连续性（从而确保学习不会断层）
### 下周计划：
尝试将匹配好的客户端的前向传播训练代码解决。


```python
import numpy as np
import math
from scipy.spatial import distance
from scipy.stats import entropy
from scipy.stats import dirichlet
#算计算能力的差异
# 随机生成四个一维点坐标
points = np.random.rand(4, 1) * 200#4个客户端计算能力随机为0-200
c = np.zeros((len(points),len(points)))
for i in range(len(points)):
    for j in range(len(points)):
        if i != j:
            c[i][j] = math.pow(points[i] - points[j],2)
        else:
            c[i][j]= -1#由于计算能力采用的是最小二乘法，所以合理情况下，不能为负数，为负数的情况指的是自己和自己，相当于矩阵的对角线
# print(c)
        
#计算距离的差异性
# 随机生成四个二维点坐标
points1 = np.random.rand(4, 2) * 200

# 计算不同点之间的距离矩阵
dist_matrix = distance.cdist(points1, points1, 'euclidean')
#设置通信范围
communication_range = 100
for i in range(len(dist_matrix)):
    for j in range(len(dist_matrix[i])):
        if dist_matrix[i][j] > communication_range  or dist_matrix[i][j] == 0:#当客户端自己和自己时，距离设成无穷，以及大于通信范围时。
            dist_matrix[i][j] = 99999999
# print(dist_matrix)

#考虑数据差异性
d = np.zeros((len(points),len(points))) 
# 生成均匀分布的数据
uniform_data =  np.random.dirichlet(np.random.uniform(0, 1, 10))

# 生成高斯分布的数据
gaussian_data = (np.random.normal(0, 1, 10))

# 生成对数分布的数据
log_data = np.random.dirichlet(np.random.lognormal(0, 1, 10))

# 生成指数分布的数据
exponential_data = np.random.dirichlet(np.random.exponential(1, 10))
 

# 对高斯分布和指数分布数据进行截断
truncated_gaussian_data =  np.random.dirichlet(np.clip(gaussian_data, 0.1, 1))#阶段
truncated_exponential_data = np.clip(exponential_data, 0.1, 1)

# 对对数分布数据进行对数变换，可以将其转化成正态分布的数据
log_transformed_data = np.log(log_data)
#再将转化成正态分布的数据进行一个截断。
truncated_log_transformed_data = np.clip(log_transformed_data, 0.1, 1)

temp = []
temp.append(uniform_data)
temp.append(truncated_gaussian_data)
temp.append(truncated_log_transformed_data)
temp.append(truncated_exponential_data)
for i in range(len(temp)):
    for j in range(len(temp)):
        if i != j:
            d[i][j] = entropy(temp[i],temp[j])
        else:
            d[i][j] = -1
# print(c)
#计算数据集大小的差异
dataset_size=np.random.rand(4, 1) * 10000
dataset_size_difference= np.zeros((len(points),len(points)))
for i in range(len(dataset_size)):
    for j in range(len(dataset_size)):
        if i != j:
            dataset_size_difference[i][j] = math.pow(dataset_size[i] - dataset_size[j],2)
        else:
            dataset_size_difference[i][j]= -1
w = dist_matrix / (1/2 * c + 1/4 * d + 1/4 *dataset_size_difference )
# print(dataset_size_difference)
for i in range(len(w)):
    for j in range(len(w[i])):
        if i == j:
            w[i][j] = 19999
        if w[i][j] == math.inf:
            w[i][j] = 10000
# print(w)
#输出权重矩阵       

from scipy.optimize import linear_sum_assignment as linear_assignment# 求解最小权重完美匹配问题
assignments = linear_assignment(w)
print(assignments)
#利用匈牙利算法成功匹配

 
dataset_size_number = np.zeros((len(dataset_size)))
# print(len(assignments[0]) // 2)
for i in range(len(assignments[0])):
     dataset_size_number[i] = math.floor(dataset_size[assignments[0][i]]) + math.floor(dataset_size[assignments[1][i]])
# print(dataset_size)
# print(dataset_size_number)
all_dataset_size=sum(dataset_size_number)/2
A=np.zeros(len(dataset_size_number))
for i in range(len(A)):
    A[i]=dataset_size_number[i]/all_dataset_size
    
L = np.zeros((len(dataset_size)))
weight = np.random.rand(1) * 10000

for i in range(len(dataset_size)):
    L[i] = (points[assignments[0][i]] / (points[assignments[0][i]] + points[assignments[1][i]])) * weight[0]
print(L)

bingzaiyiqi =np.zeros((4,2))
for i in range(len(assignments[0])):
    bingzaiyiqi[i][0]=assignments[0][i]
    bingzaiyiqi[i][1]=assignments[1][i]
print(bingzaiyiqi)
```

    (array([0, 1, 2, 3], dtype=int64), array([1, 0, 3, 2], dtype=int64))
    [4850.46858271 4450.41405403 5491.50746918 3809.37516756]
    [[0. 1.]
     [1. 0.]
     [2. 3.]
     [3. 2.]]
     
<p id="2"></p>  
    
# 3月29日周报
## 6G大会感想
### 3月23日感想
3月23日上午华为的卢建民讲了一下关于面向未来的绿色网络，其中绿色涉及方方面面，牵扯网络接口，资源分配等。当链路层设计达到天花板时需要在网络拓扑上进行一定程度的改造，尽量让收发端尽量靠近来抵御通信距离，有几种手段，一个是分布式，一个是以用户为中心的联邦学习（可以让多个节点来服务一个小区），还有就是增加一些中间节点，然后我们接着了解一下联邦学习相关情况：多样的边缘学习架构一共有以下几种：联邦学习，Decentralized learning ,模型分割学习，然后如何减少能源消耗？有两种方面：要不就是在AI上想办法，要不就是在AI和通信的结合上想办法，在AI上我们可以用稀疏化，量化，投影从而大幅度降低AI的开销。
例如在联邦学习里我们可以不把所有的参数往上传，可以采用一些方法对模型参数或者梯度进行缩减，从而降低开销。

### 3月24日感想，
3月24号上午有些论坛涉及联邦学习的一些部分，概述一下所学并提出一定感想。
在联邦学习的数字无线设计中：
1. 由于全局和本地联邦学习模型参数需要无线连接的连接交流交换，所以无线传输有故障将会影响Fl性能。
2. 基站(BS)必须接收来自设备的更新本地模型，因此传输延迟和能源消耗是一定要考虑的问题。
3. 无线网络核心要素影响学习模型：功率，宽带，接入
该论坛给出的仿真结果是当考虑FL训练参数时优化无线通信因素可以有效的改善训练时的损失，提高模型性能
但如果不考虑FL训练参数只优化无线通信因素将会导致更坏的情况。
增加RBs数量可以改善证明精度。
这将是以后我们设计联邦分割学习之后，根据这些核心要素可以引入进一步探讨，从而找到联合的最佳匹配情况。同时AI算法设计时要充分考虑网络特性，充分利用领域知识。并且在网络优化过程中可以带来AI性能的提升，是算力网络设计的必要部分。
浙江大学的张朝阳的论坛也有一些可以借鉴的东西，有一些相关的文献可以看一下
Asynchronous Federated Learning Architecture[TWC, 2022]
Hierarchical Federated Learning Architecture[GC’ 2022]
Joint Model Split and Neural Architecture Search [ICC' 2022]
Over-the-Air Split Learning Architecture [JSAC 2023]
Wireless Graph Neural Network Architecture [WCM, 2023]
异步联邦学习架构面临一些问题：（传统联邦学习不能很好的适应于无线蜂窝网络）
1.同样面临着很多异质性的难题即客户端能力的异构性和通道条件的异构性。
2.模型到达的数量过时且不确定
3.数据的异构性
解决方案：  1.服务器根据用户模型的新鲜度和重要度计算贡献矩阵，进行全局融合;
   2. 每个用户根据全局模型的新鲜度及其与训练不足模型的相关性来决定是否更新
以后采用聚合时可以除了考虑联邦平均那种聚合之外，可以在一定程度上考虑下这种聚合模式。
需求是缺乏一款适用于不同复杂无线场景的通用AI体系结构。
## 对上周的毕设工作进行了一定程度的修改
需要改变的几个点在于：
1.向前传播过程中的传播步长是只和匹配之后两者的计算能力有关，但是聚合过程那个系数之前是想着先进行一个小环反向传播，然后传给服务器，服务器再进行一次模型的加权聚合，但是这样比较繁琐，还是直接调整一下
              ${a}_{i}$               比较好。                                      
2.之前是把客户端的计算能力，数据集大小，数据集分布，以及位置信息都随机分布，但正常情况且为了和模型做对比，最好的方式应该是读取各个客户端的状态信息进行统计，然后导入，其次为了仿真方便，我们更倾向于定义传播步长即Li，那传播步长与计算能力是存在一定的关系的，故打算在仿真过程中映射权重矩阵时，找到一个与Li相关的关系。（在此这样的话，最小二乘法衡量其差距就不太可取。）        
   代码还在创作阶段，下周争取将这个匹配后的结果与sfl结合起来。
<p id="3"></p>      
    
#                     4月6日周报
对毕设代码进行了学习以及将匹配之后的客户端与联邦分割学习相结合，但是虽然跑通了，准确率存在一些问题，下周继续修改


<p id="4"></p>  

#       4月13日周报
![场景图](https://user-images.githubusercontent.com/122032188/231468034-fc1af104-4b34-4405-9189-331685e0fa8a.svg)








![cifar-noniid-2023 4 12](https://user-images.githubusercontent.com/122032188/231467692-960e2ba6-c7ee-4db8-b684-db0a0a052717.svg)











![group在不同模型下的准确率](https://user-images.githubusercontent.com/122032188/231467702-f0d22814-1ee4-4cb7-8871-f8a24dbf1a69.svg)






沈师兄指导说匈牙利算法那个配对有问题，需要改成对称匹配。代码还在调试




<p id="5"></p>  


# 4月19日周报
## WiFi下联邦学习的相关调研
##  在wifi上进行联邦学习，有什么优势?

### 无需互联网连接：
在WiFi环境下，设备可以直接通过WiFi网络连接，而无需经过互联网连接。这意味着，在WiFi环境下进行联邦学习可以避免因互联网连接不稳定或不可靠而导致的数据传输延迟、带宽瓶颈等问题，提高数据传输效率和模型训练速度。

### 保护数据隐私：
在联邦学习中，本地设备的数据不需要上传到中央服务器，而是在本地进行模型训练和更新。在WiFi环境下，设备可以通过本地WiFi网络进行通信，而无需将数据上传到公共互联网上，从而可以更好地保护本地数据的隐私。

### 支持本地计算：
在WiFi环境下，设备可以利用本地计算资源进行模型训练和更新，而无需依赖中央服务器。这意味着，在WiFi环境下进行联邦学习可以实现更加分散和灵活的计算，提高系统的可扩展性和鲁棒性。

### 支持边缘计算：
在WiFi环境下，设备可以作为边缘节点，利用其所处的环境信息和WiFi信号特征进行感知和数据采集。这可以实现更加分散和分布式的数据感知和分析，提高系统的实时性和精度。

综上所述，在WiFi上进行联邦学习具有数据隐私保护、本地计算支持、边缘计算支持、以及无需互联网连接等优势，可以更好地适应不同应用场景和数据特征。

## 在wifi 上进行联邦学习有什么劣势?
在WiFi上进行联邦学习也存在以下一些劣势：

### WiFi信号波动：
在WiFi环境下，信号波动是一个普遍存在的问题，特别是在高峰期和人流量大的场所。这可能会导致数据传输延迟、数据包丢失等问题，影响模型训练和更新的效率和精度。

### 数据分布不均：
在WiFi环境下，设备的位置和使用情况可能存在较大的差异，导致数据分布不均。这可能会影响模型的泛化能力和准确性，需要采用相应的数据采样和模型聚合策略来解决。

### 设备异构性：
在WiFi环境下，设备类型和系统环境可能存在较大的异构性，导致模型的可移植性和兼容性问题。这需要采用相应的模型适配和转换策略来解决。

### 通信开销较大：
在WiFi环境下，设备需要通过WiFi网络进行通信，而WiFi网络的通信开销较大，特别是在数据量较大或通信频繁的情况下。这可能会导致通信成本过高或无法承受，需要采用相应的通信压缩和优化策略来解决。

综上所述，在WiFi上进行联邦学习也存在一些劣势，需要根据应用场景和具体问题进行相应的优化和解决。


## 检索的一些文献：
### wifi 传感和federated learning 的结合
<img width="1110" alt="WiFederated_ Scalable WiFi Sensing Using_Edge-Based Federated Learning (1)(1)(1)" src="https://user-images.githubusercontent.com/122032188/232421979-0aaf55d7-d74c-4301-a6f2-1294e60040b6.png">


























































































































### Improving TCP Performance Over WiFi for Internet of Vehicles: A Federated Learning Approach
为了提高车联网的性能，我们提出了一种新型的通信效率和隐私保护的联合学习框架，该框架通过局部交换输入、输出和学习参数来训练车辆学习模型。此外，我们使用分析建模作为一种工具来推理和开发所需的车联网场景，并通过考虑WiFi网络上的TCP CUBIC流来稳定其数据流动力学，以证明我们的想法。

<img width="745" alt="屏幕截图 2023-04-17 161736" src="https://user-images.githubusercontent.com/122032188/232426494-fb7419e6-5779-45d6-ab3c-a3a52cb780b8.png">



在车联网场景中，带有WiFi接入点(ap)的车辆通过路边单元(RSUs)与联邦协调器和互联网连接。车辆内部的学习模块进行局部训练，并使用TCP CUBIC与其他车辆进行通信，形成一个邻近车辆的自组织网络。

总结：开发了一种WiFi AP车载概念车，并通过联合学习方法研究了其可行性。我们的数学分析为开发可实现的网络控制联合学习算法提供了重要的见解，该算法与现有的wifi标准和tcp协议兼容。对我们提出的算法的车联网系统动力学的收敛条件的详细分析需要进一步的研究，并正在进行中。


### FLoc: Fingerprint-based Indoor Localization System under a Federated Learning Updating Framework
基于指纹的室内无线定位技术在过去的十年中取得了巨大的突破。但它存在一个固有的问题，即由于动态环境和WiFi设备不稳定，定位精度会随着时间的推移而急剧下降。为了保持定位的准确性，研究人员设计了很多方法来更新定位模型，例如基于众包的模型更新。不幸的是，他们在更新过程中没有考虑到隐私问题。这将导致窃听者根据更新模型猜测位置提供商的私人信息的威胁。为了在保证定位精度的前提下避免侵犯隐私的风险，我们提出了一种基于指纹的室内定位系统FLoc，该系统通过联邦学习框架更新定位模型。在FLoc中，每个提供商在自己的设备中维护一个本地本地化模型。他们将定期加密更新参数，并将它们共享到一个公共模型服务器。在模型服务器上，它聚集本地模型的加密信息以维护一个通用模型，该模型将被发送回本地设备以进行下一次更新迭代。我们在ap未知的实验室走廊中评估FLoc。实验结果表明，FLoc具有相当的定位性能。此外，它可以成功地保护提供商的隐私，因为传输的信息都是加密的。提出了一种基于联邦学习的WiFi室内位置指纹定位系统FLoc。该系统在更新基于指纹的定位模型时，着重于降低隐私泄露的风险。为了避免私人位置信息的泄露，FLoc使用了一个联邦学习框架来更新定位模型，并且只需要更新模型参数，而不需要移动设备的位置指纹。我们在实验室走廊里评估了FLoc。实验结果表明，联合学习可以与传统的深度学习相媲美。此外，该算法通过更新定位模型来解决不一致问题，从而适应动态环境和不稳定信号。此外，FLoc依靠联邦学习保护移动设备用户的位置隐私。最后，打算在未来的工作中考虑不同移动设备的差异。
### Distributed Spectrum and Power Allocation for D2D-U Networks: A Scheme based on NN and Federated Learning
研究了一种基于无授权带宽(D2D-U)的设备间通信方案。为了在保证 D2D-U 链路之间的公平性和与 WiFi 网络的和谐共存的同时，提高未授权频段的频谱利用率(SE)并适应其分布式结构，提出了一种分布式功率与频谱联合方案。特别地，定义了一个价格参数，通过在线训练神经网络(NN)根据信道状态和流量负载对每个 D2D-U 对进行更新。通过无监督自迭代和联邦学习两种方式对神经网络参数进行更新，以保证网络的公平性和协调性。然后，一个关于频谱和功率的非凸最佳化问题被公式化，并在每个 D2D-U 链路上求解，以最大化其自身的数据传输速率。
本文提出了一种具有自适应价格调整机制的分布式功率和频谱分配机制，在D2 D-U链路上采用无监督的在线学习结构来估计所有感知到的未授权信道的价格，以重用未授权频谱上的频谱资源来提高D2 D-U系统的性能。为了提高系统的稳定性和性能，采用基于联邦学习的方法，建立功率优化模型和频谱优化模型，并通过D2 D-U对进行求解，从而实现对非授权频谱的接入。数值仿真结果表明，该算法在保证WiFi系统公平性和不同D2 D-U用户间公平性的前提下，使D2 D-U链路的数据速率最大化。
